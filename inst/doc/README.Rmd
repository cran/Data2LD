---
title: "How to Use Matlab Function \code{Data2LD}"
author: "J. O. Ramsay"
date: "2018-05-30"
output: html_document
---

```{r} setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction: What does \code{Data2LD} do?

\code{Data2LD} estimates the parameters that define a linear differential equation that models observations of one or more curves evolving over time, space or another continuum.  

Below we offer a basic introduction to systems of linear differential equations, but it would be useful of obtain the text Ramsay and Hooker (2015) for additional background on linear differential equations and examples of data analyses using models of this nature.  

You will need to have a working knowledge of the functional data software package \code{fda} in order to implement a \code{Data2LD} analysis.  If you are a little shakey on the subject of functional data analysis, you can consult Kokowszka, P. (2017) and Ramsay, Hooker and Graves (2009) as introductory references or Ramsay and Silverman (2005) as a more complete source.

## The architecture of a linear differential equation

### A single differential equation

A single linear differential equation has a derivative of order $m$ on the left side of the equation, which we shall denote by $D^m x(t)$ instead of using the older and more cumbersome notation $d^m x/d t^m.$  Although $D^m x(t)$ is a function of time or some other continuum, we will often minimize the clutter in our notation by dropping "$(t)$" from our expressions.  

The right side of the equation consists of a sum of terms, each being the product of of a function $\beta_j$ and an order of derivative of the variable that is less than the order $m$ that is on the left side.

In the simplest situation, order $m = 1$ and there is only a single term on the right side, namely $\beta(t) x(t)$.

The coefficient or multiplier functions $\beta_j$ can be functions of $t$, or of any other external variable, but the most frequent case in practice is that they are constants.  What they cannot be is functions of the value $x$ or of any of its deriavtives.  They are often called *rate* functions because they control the speed with which the values of $x$ reacts to a change in input.  We describe input to equations below.  

What makes the equation linear is (1) that a sum of terms is involved, and (2) each term is a product of a multiplier $\beta(t)$.  For example the differential equation $Dx(t) = \beta*x(t)*[K - x(t)]$ is nonlinear because it involves the square of $x$.

### Systems of linear differential equations

A system of differential equations involves $d$ variables $x_i, i=1,\ldots,d$.  We allow the left side to have an order of derivative $m_i$ that varies from one equation to another.  

The right side of the $i$th equation is a sum of terms involving derivatives $D^k x_j$ of orders $k$ less than $m_j$.  Although there is the potential for a very large number of such terms if $d$ is at all large, this usually does not happen.  Rather the terms for equation $i$ involve only one or two variables other than the variable $x_i$ on the left side of the equation, as well as terms involving that variable itself.

### Forcing or input terms to systems of equations

We consider, too, that one or more of these functional variables $x_i$ may be in a linear causal relationship with some known input or covariate variables $u_{i\ell}, \ell = 1,\ldots,L_i$ that are also observed.  These will be incorporated into the relevant differential equations as additional explanatory terms, and they are called *forcing* variables.  Each $u_{i\ell}$ is multiplied by a coefficient function $\alpha_\ell$ which, like the rate functions, may vary over time and also over the value of any external variable, but not over values of any variables $x_i$ in the system.  

A forcing function may be simply the constant 1, in which case the focus is on estimating its coefficient function $\alpha_{\ell}$ as an unknown input to the equation.  We refer to this situation as *dynamic data smoothing*.

If an equation does not have any forcing functions, it is called *homogeneous* or *autonomous*.  If it does, it is called *nonhomogeneous* or *nonautonomous* or, more simply, *forced*.  The autonomous portion of a differential equation is said to define the *dynamic behavior* of the variable, including how it responds to variation in any forcing functions that may be present.  We  refer to terms involving derivatives of any of the variables $x_j$ as *homogeneous* terms.

Chapter 3 of Ramsay and Hooker (2017) can be consulted for more details.

## Example systems

Here are some simple examples that may help to clarify the structure of linear differential equation systems, and illustrate the notation that we use.
  * First order unforced
      : $Dx = \beta x$
  * First order with single forcing
      : $Dx = \beta x + \alpha u$
  * First order with multiple forcing
      : $Dx = \beta x + \alpha_1 u_1 + \ldots +  \alpha_L u_L$
  * Second order unforced
      : $D^2x = \beta_1 x + \beta_2 Dx $
  * Second order unforced with contribution from only x
      : $D^2x = \beta_1 x$
  * Second order forced
      : $D^2x = \beta_1 x + \beta_2 Dx  + \alpha u$

All these examples involve only a single variable, and we want to extend them to allow for more than one variable with mutual additive effects on each other.  Now we will need two subscripts on each coefficient, the first of which pertains to the variable being affected, and the second to the variable producing the effect.  In fact, for higher order equations, we will also need a third index that specifies the order of derivative.

  * Two first orders unforced
    : $Dx_1 = \beta_{11} x_1 + \beta_{12} x_2$ 
    : $Dx_2 = \beta_{21} x_1 + \beta_{22} x_2$
  * Two first orders with single forcing
    : $Dx_1 = \beta_{11} x_1 + \beta_{12} x_2 + \alpha_{11} u_{11}$ 
    : $Dx_2 = \beta_{21} x_1 + \beta_{22} x_2 + \alpha_{21} u_{21}$
  * A first order and a second order unforced
    : $Dx_1   = \beta_{11} x_1 + \beta_{12} x_2$ 
    : $D^2x_2 = \beta_{21} x_1 + \beta_{220} x_2 + \beta_{221} Dx_2$
Notice in the third example that, because variable $x_2$ has a second order equation, there can be a contribution from the variable itself (that is, $D^0 x_2$) as well as from its first derivative.  The third index can take values from 0 to $m-1.$

But, thankfully, most systems used in practice will not need this level of complexity.  In fact, typically, the majority of these contributions are not in the equation at all.  Moreover, some of the elements in the equation will be associated with known rate functions, for example, with values that may have been determined by earlier experiments.  

Often a specific rate function $\beta$ or forcing function coefficient function $\alpha$ may appear more than once in a system of equations, in which case the notation for specifying the equations may have to be modified so as to make this clear.  But it's still important to keep the three-index notation $\beta_{i_1,i_2,j}$ in mind since, in summary, on the right side of equation $i_1$ there is the potential to have a contribution from the $j$th derivative of variable $i_2$, as well as from forcing functions $u_{i_1 \ell}, \ell = 1, \ldots, L_{i_1}$ modulated by multiplicative coefficient $\alpha_{i_1 \ell}$.  

Here, in summary, are the facets of a linear differential equation system that an \code{Data2LD} analysis can handle:
  * single or multiple equations
  * first order or higher order
  * homogeneous or forced equations
  * constant or time-varying coefficients
Future versions of \code{Data2LD} will allow other possibilities, such as multiple observations at times, and smoothing or regularization of estimated rate or coefficient functions.

## Functional observations

A single functional observation is a set of $n$ values $y_j$ at a set of time points $t_j$ contained with some interval that we shall assume, without losing any generality, ranges from 0 to $T$.  For simplicity, we shall also assume that the observations are univariate, that is, each $y_j$ is a single real number.  We also assume that the times are strictly ordered,  so that $t_j < t_{j+1}$.  What makes the observations functional is that a smooth function $x(t)$ underlies these data, and that $y_j$ reflects the function value $x(t_j)$.  

\code{Data2LD} assumes the classic relation $y_j = x(t_j) + e_j$
where the "errors" or "residuals" have a distribution with mean $\mu = 0$, variance $\sigma^2$  that is finite, and that their distribution is independent of that of the $x(t_j)$'s. These assumptions justify the use of least squares approximation to the data, which \code{Data2LD} implements.

Note that not all of the $d$ functions $x_i, i=1,\ldots,d$ may be observed, a situation that is quite common in applications.  

# What are the steps in a typical \code{Data2LD} analysis?

Here we take you through the steps and decisions required to execute an \code{Data2LD} analysis and explore the results.   Also, you might be helped by following through the code in the next Section for either the single variable refinery data, or for the two-variable the cruise control example.  The distribution of \code{Data2LD} contains a number of sample analyses that illustrate the use of \code{Data2LD} in live data analyses.

## Define the problem

This is where you set up the differential equation, perhaps the most important step of all.  

Your greatest hazard will be exuberance!  It is extremely easy to over-parameterize a model defined by a differential equation, and in the writer's experience, a large portion of published equations are.  Whether or not a model is over-parameterized, so that certain coefficients and combinations of coefficients cannot be estimated, will depend on the configuration of the data.  

So begin with the simplest possible equation or system that you can imagine has anything to say about the data, even if it is known to be only a caricature.  Check the estimated system using methods described below to see that is well-defined by the data, and then consider only a few elements to the equation, preferably one at a time, again accompanied by careful confirmation of identifiability.  You have been warned!

## Specify the observation interval and observation times

The observation values and the times of observation are specified in a list array of length $d$, the number of variables in the system.  It is usual for some variables not be observed, and the corresponding lists will be empty as a consequence.  The number of spacing of times can vary from one list to another, but even if they are the same for all variables, this information is required in list corresponding to an observed variable.

It can happen that observations do not have a one-to-one correspondence with variables.  For example, an observation may be of the sum of two variables.  Unfortunately, function \code{\code{Data2LD}} cannot accommodate such data configurations, but this is a target for future development.

## Setting up the \code{coefList} list array defining rate functions and forcing function multipliers

As we noted above,  some rate functions $\beta$ and forcing coefficient functions $\alpha$ can appear at more one place in a system of equations.  More generally, the number and types of these coefficients can vary from one equation to another.  These considerations imply that we need to define these $\beta$ and $\alpha$ coefficient functions first, before setting up the equations themselves by defining their terms.  

Each rate or coefficient function is defined by one or more parameters.  Some functions will have parameters that must be estimated by \code{Data2LD}, and some others will be defined by parameter values treated as fixed.  All parameter values will need to be specified, however, since even those to be estimated must have initial values that will be modified in the course of optimizing the fits to the data.  It will often be the case that rate or coefficient functions are simple constants, and thus require only a single parameter value.  A more general but still simple case is where the function is defined by a basis function expansion, and therefore can be considered as a functional data object (see references above for more information on functional data objects if needed).

The most general case is one in which the user defines the function by providing a function handle.  In this case, and if these parameters require estimation, a second function handle is also required for the partial derivative of the function with respect to the parameters that define it.

Often terms contain a constant, such as -1.  For example, the simple first order equation is often specified as $Dx(t) = -\beta x(t)$ because, if $\beta$ is positive, the variable will respond to a sharp change in input by a more gentle exponential approach to a new level.  Therefore we accommodate the use of fixed constants in a term's definition.

Each rate or coefficient function is specified as a \code{list} object within a list of a single-dimension list array of length equal to the total number of these functions.  The \code{list} object with these named fields:
parvec :  a numeric vector containing the initial values of each of the parameters defining the coefficient function.  If the function is a functional data object, this will be the vector of values of the coefficients defining its basis expansion.  If the function is just a constant, then only a single real value is required, and this is taken as defining a constant functional data object.
estimate :   a logical or integer value indicating whether or not the function is to be treated as fixed.  If an integer is supplied, zero indicates fixed and any other value indicates estimated.
coeftype :   This field is currently optional, and can contain any of the strings \code{alpha}, \code{beta}, \code{alpha}, \code{force}, \code{homo}, \code{homog}, or \code{homogeneous}.
fun :   one of:
    * functional basis object of type \code{basis}
    * a functional data object of type \code{fd}
    * a functional parameter object of type \code{fdPar}
    * a \code{list} object with these named fields:
    fd   :   a functional handle for the Matlab code defining the value of the function
    Dfd  :   a functional handle for the Matlab code defining the value of the derivative of the function with respect to its parameters
    more :   any additional information required for the code defining the function value

Each function \code{list} object can be set up manually, which is not a bad idea for keeping track of what you have done, but we also provide a function \code{make.coef} that will set up the \code{list} object in a single line of code.  Its call is \code{make.coef(fun, parvec, estimate, coeftype)}.

There is lots of scope for making mistakes in the setup, and consequently a function \code{coefCheck} is provided that should be called after the list array is defined, and is also called automatically within \code{Data2LD}.  It can be invoked by the command \code{coefCheck(coefList)}.

## Setting up the \code{modelList} list array defining the system of equations

Argument \code{modelList} specifies the structure of the system of differential equations in roughly the same way that you would write down the equations one after the other.  It is a single-dimension list array of length equal to the number of equations.  

Each list in \code{modelList} contains a list object that in turn contains the essential information about the corresponding equation.  These seven items are named fields, and are as follows, with the name appearing in bold face and description of the object following:
XList:  This is a one-dimension list array (list), with each list containing a list object that specifies a term in the equation that involves either $x_i$ or a derivative $D^jx_i$ of the variable.  We call these the *homogeneous} or *autonomous} terms in order to distinguish them from the terms involving forcing functions.  The length of the \code{XList}  list array is equal to the number of homogeneous terms in the equation.  The details of the list object in a list of \code{XList} will be specified in the next paragraph.
FList:  This is also a one-dimension list array, with each list containing a list object, to be described below, that specifies the nature of a forcing function term.  If the equation does not have forcing term, an empty list $\{\}$ is used. The details of the list object in a list of \code{Fterm} will be specified in the next paragraph.
order: a positive integer specifying the highest order derivative $m$ in the equation, the expression $D^m x_i$ typically appearing to the left of the equal sign for equation $i$.
name: A character string to be used as a name for the variable.  If not supplied, it defaults to \code{x1}, \code{x2} and so on.
weight: a positive number specifying a weight to used in defining the total fit to the data.  This is required when variables differ widely in scale, as often happens.  If not supplied, it defaults to one.
nallXterm: an integer specifying the number of homogeneous terms in this equation.  
nallFterm: an integer specifying the total number of forcing terms in this equation

### The \code{XList} object}

Now let's look at the list object that is contained in a list in \code{XList}.  

The following four fields are required to be set up by the user:
variable :   This field contains an integer specifying which of the variables is involved in this term.  Any of the variables are candidates, and they may appear in any order.  It is usual to have a contribution from the equation's variable itself and/or one or more of its derivatives, but other variables may also appear.
derivative :  The order of the derivative of the variable in the term. This derivative order must be less than that variable's highest derivative order.
ncoef :   The index of the function specification in the list array \code{coefList}.  
factor :   An optional specification of a fixed constant multiplier for the term.  This is often either -1 or 1, but may be any value.  It defaults to 1.  

Again we supply a single line command \code{make.Xterm(variable, ncoef, derivative, factor)}
that can do this set up of a single homogeneous term for you.

### The \code{FList} object}

The list objects contained in the lists of the \code{FList} list array specify the forcing functions and the coefficients $\alpha(t)$ that multiply them.  

There are three required fields for each forcing function:
\begin{description}
Ufd :   A functional data object of the \code{fd} class specifying the forcing function.  If there are replications involved, this object may have the same number of  replications, or it may be a single function, in which case, this function is used for all replicates.
ncoef :   The index of the function specification in the list array \code{coefList}.  
factor :   An optional specification of a fixed constant multiplier for the term.  This is often either -1 or 1, but may be any value.  It defaults to 1.  
\end{description}

The command that will set this up automatically is \code{make.Fterm(variable, ncoef, Ufd, factor)}.

Finally, these two list arrays plus the other five objects that define a single linear differential equation must be combined into \code{list} object that is within the respective list of the over model list array that defines the complete system.  A single line command that will do this for you if you prefer is \code{make.variable(name, order, XList, FList)}.  The \code{weight} field can be set manually if you need to do so, and the remaining two fields \code{nallXterm} and \code{nallFterm} are automatically set when you use the \code{modelCheck} function described below.

The function \code{modelCheck} should be used immediately after the model list array is specified, and it will be called automatically within \code{Data2LD}.  It can be invoked by the command \code{modelCheck(modelList, coefList)}.

## Select one or more basis systems for representing the solution(s)

There are two classes of basis systems in an \code{Data2LD} analysis: the rate or coefficient function bases and the variable bases.  The variable bases define the estimate of the solution functions $x_i$.  Here some care and thought is required.  The basis system is not determined so much by the data, as it would be in normal smoothing, but rather by what behaviour the variable must exhibit in order to allow an accurate solution to the equations.  Often, for example, highly localized curvature is present and especially where a forcing function is discontinuous, as it often is.  In such a condition, high knot density for a B-spline expansion is required, or even multiple knots at a known specific location.  Both the cruise control and the head impact examples exhibit this problem.  A good quality final choice for a variable system may require considerable experimentation.

## Compute starting values for estimated coefficients using derivative matching 

This is an optional step, since \code{Data2LD} often works fine with simple initial coefficient values like zero, and supplying good initial values often only saves one or two iterations.  

However, if good initial values are considered important, these can be constructed by a process that we call *gradient matching.}  This involves an initial smoothing of the data for each observed variable, with a view to estimating the highest required derivative.  Then the derivatives are converted to functional data objects, and these are used in the arguments of the \code{fRegress} function that fits a concurrent linear model. \cite{Ramsay:09} can be consulted for further details, and the cruise control examples show how this is done in that context.

## Preliminary computations of four-way tensors

In this as well as in many algorithms, certain quantities need only be computed once, and once set up, can be reused each time a function is invoked.  In the case of \code{Data2LD},  the integral of each product of terms in each equation must be evaluated over and over again, and the approximation of the integral can be a time-consuming affair.  But this computational load can be greatly reduced by computing once and for all the four-way array of integrals of products of four basis functions, where the basis functions involved are those the $\beta$ and/or $\alpha$ bases and at the same time those of possible pairs of solution basis functions. 

## A simple example: The refinery data

Our simplest example of a setup is for the analysis of the refinery data described in our references and available for analysis in our distribution package.

The single differential equation is $Dx(t) = -\beta x(t) + \alpha u(t)$.  Note that both rate function $\beta$ and forcing coefficient $\alpha$ are constants.  Moreover, by convention in the field of chemical engineering, a minus sign appears in front of $\beta$, which is expected to be constant.  The homogeneous part of the equation is the differential equation for exponential decay.  The data are observations of fluid level in a tray in a refinery cracking tower, and the forcing function is a valve setting which is close until time 67 minutes when it is opened.  The forcing function is specified as a functional data object \code{Ufd}.  The observations are recorded until 193 minutes.  Both coefficients will be estimated.

These commands set up the data that we want to analyze:
```{r}
N <- 194
rng <- c(0,193)
TimeData <- RefineryData[,1]
TrayData <- RefineryData[,2]
ValvData <- RefineryData[,3]
par(mfrow=c(2,1))
plot(TimeData, TrayData, type="p") 
lines(c(67,67), c(0,4.0), type="l")
plot(TimeData, ValvData, type="p")
lines(c(67,67), c(0,0.5), type="l")
```

This model assumes that a single forcing function is deriving the output.  This is the valve setting, which is a step function changing its level at time 67.  The following code sets up a functional data object for this input function.

```{r}
Valvbreaks <- c(0,67,193)
Valvnbasis <- 2
Valvnorder <- 1
Valvbasis  <- create.bspline.basis(rng, Valvnbasis, Valvnorder, Valvbreaks)
Valvefd    <- smooth.basis(TimeData, ValvData, Valvbasis)$fd
par(mfrow=c(1,1))
plot(TimeData, ValvData, type="p")
lines(c(67,67), c(0,0.5), type="l")
lines(Valvefd)
```

We now begin to defining the coefficients.  These will be contained in a list array of length two containing the specifications of the two multiplier functions, one for the multiplier of the homogeneous term and one for the multiplier of the input function.  For comparison purposes, we construct the first coefficient specification by manually defining the fields of its \code{list} object, and use the function \code{make.coef} for the second.
```{r}
  conbasis <- create.constant.basis(rng)
  confdPar <- fdPar(conbasis)
  # manual construction of first coefficient
  coefList1 <- list(fun=confdPar, parvec=0, estimate=TRUE)
  # one-line construction of second coefficient
  coefList2 <- make.coef(confdPar, 0, TRUE)
  # assemble into a list-vector of length 2
  coefList      <- vector("list",2)
  coefList[[1]] <- coefList1
  coefList[[2]] <- coefList2
  # check the resulting coefficient list
  coefResult <- coefCheck(coefList)
  coefList   <- coefResult$coefList # the checked coefficient list
  ntheta     <- coefResult$ntheta  # the number of parameters to estimate
  print(paste("The number of parameters =",ntheta))
```
Here the variable \code{ntheta} will have value 2.

Actually, it is necessary that the rate constant $\beta$ multiplying the tray level be positive.  Although there is no danger in this example that it will ever go non-positive, we can instead be sure of that by using the following definition that uses a \code{list} object for the \code{fun} field of \code{coefList1}:
```{r}
  #funList       <- list(fun=fun.explinear, Dfun=fun.Dexplinear)
  #coefList1     <- make.coef(funList, 0, TRUE, "beta")
  #coefList2     <- make.coef(confdPar, 0, TRUE, "alpha")
  #coefList      <- vector("list",2)
  #coefList[[1]] <- coefList1
  #coefList[[2]] <- coefList2
```
The two short and simple functions that appear in the definition of \code{funList} define the exponential of a basis function expansion and the corresponding derivative, and are distributed with the code package.

Next we define the list object of length 1 containing the specification of the single homogeneous term of the model.
```{r}
  # define the single homogeneous coefficient
  Xterm = list(variable=1, ncoef=1, derivative=0, factor=-1)
  # or
  Xterm <- make.Xterm(1, 1, 0, -1) # coefList[[1]], derivative 0, variable 1, factor -1
  XList <- vector("list", 1)
  XList[[1]] <- Xterm
 ```
  
 Then we define the list object containing the specification of the single forcing term.
```{r}
  # define the single forcing coefficient
  Fterm <- list(ncoef=2, Ufd=Valvefd)
  # or
  Fterm <- make.Fterm(2,Valvefd)  # fd object Ufd, coefList[[2]], factor 1
  FList <- vector("list", 1)
  FList[[1]] <- Fterm
```  
  Now we assemble these terms into the definition of the first order forced linear differential equation.
```{r}
  #  assemble these into a list object for the variable
  modelList1 = list(name="x", order=1, XList=XList, FList=FList)
  # or 
  modelList1 <- make.variable("x", 1, XList, FList)
```

We conclude the setup of the model by placing the variable definition into a list object of length one, and then checking the structure of this definition to invoking \code{modelCheck}.
```{r}
  # place this variable list into a model list of length 1
  modelList      <- vector("list",1)
  modelList[[1]] <- modelList1
  # check the model list
  modelList <- modelCheck(modelList, coefList)
```

We now load the observation times and the data, contained in vectors \code{tvec} and \code{xvec}, respectively into a list object \code{yList}.
```{r}
  yList1 <- list(argvals=TimeData, y=TrayData)
  yList  <- vector("list",1)
  yList[[1]]  <- yList1
```

We also define the basis for the solution and load it into a list object of length one.
```{r}
  Xnorder <- 5
  Xbreaks <- c(0, 67, 67, 67, seq(67, 193, len=15))
  Xnbasis <- 22
  Xbasis  <- create.bspline.basis(rng, Xnbasis, Xnorder, Xbreaks)
  XbasisList <- vector("list",1)
  XbasisList[[1]] <- Xbasis
```

Here a little explanation about our order and knot choices for represent $x(t)$ is needed.  We use order 5 B-splines as a basis because we want the first derivative to be smooth nearly everywhere, except at the time 67 of the valve opening when an abrupt change in the input forcing function takes place.  There we have to allow the first derivative to be continuous but not its higher derivatives.  We achieve this by putting four knots at the same value, namely 67 minutes.  After time 67, 13 equally spaced interior knots are used, but before then, where the function is flat, we have no interior knot.

Finally, we invoke \code{Data2LD} once to ensure that everything is working, and also to build the four-way tensor objects may be rather time-consuming to compute, but once computed can be stored and used over and over again.  This is a process called *memoization*, and it can save a great deal of computation time.
```{r}
  Data2LDList <- Data2LD(yList, XbasisList, modelList, coefList)
```

Recall that this simple model has only one homogeneous and one forcing coefficient.  Here we could simply assign the XList and FList objects these single list objects \code{Xterm} and \code{Fterm}, respectively.  More generally, if there are more than one homogeneous or more than one forcing coefficient, we would have to initially set up an object that is a vector of list objects, and then assign each position in the vector to its respective term list object.

For example, suppose that the simple equation above was of the second order and had two homegeneous terms, one for the zero order derivative and one for the first derivative.  Then we would set up its \code{XList} object as follows:
```{r}
  Xterm1 <- make.Xterm(1, 0, 1, -1) # coefList[[1]], derivative 0, variable 1, factor -1
  Xterm2 <- make.Xterm(2, 1, 1, -1) # coefList[[2]], derivative 1, variable 1, factor -1
  XList    <- vector("list",2)
  XList[1] <- Xterm1
  XList[2] <- Xterm2
```

## A two-variable system: The cruise control model

This example is not much more complicated, but does illustrate how one rate function can appear in more than one place in a system.  It models how a simple feedback system works, in this case the accelerator pedal in a car.  The two variables are the speed ($S$) of a car and feedback ($C$) as the driver manipulates the accelerometer to change the target speed ($S_0$).  The data consist of 41 simulated observations for each variable, distributed uniformly of the time interval [0,80].  The input variable is the desired speed or *set point* $S_0(t)$, and it is changed at times 0, 20, 40 and 60 to speeds 60, 40, 80 and 60 kilometres per hour, respectively.

The two differential equations are:
$$DS(t) = -\beta_{SS} S(t) + \beta_{SC} C(t)$$
$$DC(t) =  \beta_{CS} S(t) - \beta_{CC} C(t) + \alpha_{C} S_0(t)$$
where $\beta_{SS} = 1$, $\beta_{SC} = 1/4$, $\beta_{CS} = -1$, $\beta_{CC} = 0$ and $\alpha_C = 1.$
The homogeneous part of the speed equation is again that of exponential decay, and it is forced by the control variable.  The homogeneous part of the control equation is zero, and it is forced by the difference between the set point and the current speed.  The system works by increasing $C$ when the current speed is less than the target and decreasing it when it is greater.  The increase is passed into the speed equation as an additive forcing by $C$ modulated by the value of $\alpha_S$.  Because of the exponential decay dynamics of $S$, the speed will approach the new speed target with an exponentially decreasing rate.

```{r}
T     <- 80  #  seconds
rng   <- c(0,T)
n     <- 41
tobs  <- seq(0,T,len=n)
Sdata <- c( 0.4, 19.0, 34.0, 49.4, 56.2, 57.1, 59.5, 57.3, 57.7, 60.3, 61.5, 59.9, 46.9, 
           44.4, 41.6, 36.9, 39.4, 36.4, 41.7, 38.2, 40.2, 49.4, 64.2, 70.8, 77.3, 79.9,
           82.8, 79.4, 75.7, 78.3, 82.7, 72.6, 70.2, 64.3, 64.7, 56.8, 59.9, 57.6, 65.8,
           61.7, 62.0)
Cdata <- c( -8.5, 103.8, 172.8, 219.0, 224.7, 240.1, 221.4, 236.4, 233.4, 227.5, 243.3,
           206.3, 181.9, 159.2, 173.2, 164.5, 158.2, 160.2, 157.9, 146.0, 158.4, 224.8,
           268.7, 290.9, 307.1, 300.4, 326.4, 323.8, 319.7, 319.7, 313.3, 292.3, 260.6,
           244.1, 255.0, 239.8, 235.9, 237.8, 233.2, 231.0, 260.2)
yobs  <- cbind(Sdata,Cdata)
nfine <- 101
tfine <- seq(0,T,len=nfine)
Strue <- c( 0.0,  3.7, 11.5, 20.2, 28.5, 35.6, 41.4, 46.1, 49.7, 52.5, 54.5, 56.1, 57.2,
           58.0, 58.6, 59.0, 59.4, 59.6, 59.7, 59.9, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0,
           58.8, 56.2, 53.3, 50.7, 48.3, 46.2, 44.6, 43.4, 42.5, 41.8, 41.3, 40.9, 40.6,
           40.4, 40.3, 40.1, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 42.4,
           47.5, 53.4, 58.9, 63.6, 67.5, 70.7, 73.1, 75.0, 76.4, 77.4, 78.2, 78.7, 79.1,
           79.4, 79.6, 79.8, 79.9, 79.9, 79.9, 80.0, 80.0, 80.0, 80.0, 80.0, 78.8, 76.2,
           73.4, 70.7, 68.3, 66.3, 64.7, 63.4, 62.5, 61.8, 61.3, 60.9, 60.6, 60.4, 60.3,
           60.2, 60.1, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0)
Ctrue <-  c(   0.0,  46.9,  89.0, 124.3, 152.8, 175.0, 192.1, 205.0, 214.6, 221.8, 
             227.0, 230.7, 233.5, 235.4, 236.8, 237.8, 238.6, 239.1, 239.4, 239.7, 
             240.0, 240.1, 240.1, 240.1, 240.1, 239.3, 224.2, 210.2, 198.5, 189.1, 
             181.7, 175.9, 171.6, 168.3, 166.0, 164.2, 163.0, 162.1, 161.4, 161.0, 
             160.6, 160.3, 160.1, 159.9, 159.9, 160.0, 160.0, 160.0, 160.0, 160.0, 
             160.7, 191.0, 219.1, 242.6, 261.6, 276.5, 288.0, 296.6, 303.1, 307.9, 
             311.4, 313.9, 315.7, 317.1, 318.1, 318.7, 319.1, 319.5, 319.7, 319.8, 
             319.9, 319.9, 320.0, 320.0, 320.0, 319.6, 304.3, 290.3, 278.6, 269.2, 
             261.7, 256.0, 251.6, 248.3, 246.0, 244.2, 242.9, 242.0, 241.3, 240.9, 
             240.6, 240.3, 240.2, 240.1, 240.1, 240.0, 240.0, 240.0, 240.0, 240.0, 
             240.0)
yfine <- cbind(Strue,Ctrue)
# plot the data
par(mfrow=c(2,1))
plot(tobs, yobs[,1], type="p", pch="o", xlab="", ylab="Speed")
lines(tfine, yfine[,1])
plot(tobs, yobs[,2], type="p", pch="o", xlab="Time (seconds)",ylab="Control")
lines(tfine, yfine[,2])
```

Set up the set-point forcing function.  The set-point function uses an order 1 step function B-spline basis in order to define a function that is piecewise constant.  The knots are placed at the points where the set-point changes values.

```{r}
steporder  <- 1  #  step function basis
stepnbasis <- 4  #  four basis functions
stepbreaks <- c(0,20,40,60,80)
stepbasis  <- create.bspline.basis(rng, stepnbasis, steporder, stepbreaks)
stepcoef   <- c(60,40,80,60)  # target speed for each step
SetPtfd    <- fd(stepcoef, stepbasis)  # define the set point function
```

Here we use the handy function \code{make.coef} to set up each rate or forcing coefficient. We add in a homogeneous term $\beta_C$ multiplied by zero and not estimated just for purposes of illustration.

```{r}
 conbasis    <- create.constant.basis(rng)
 confdPar    <- fdPar(conbasis)
 coefListSS  <- make.coef(confdPar,   1, TRUE)  
 coefListSC  <- make.coef(confdPar, 1/4, TRUE)  
 coefListAC  <- make.coef(confdPar,   1, TRUE) 
 coefListBC  <- make.coef(confdPar,   0, FALSE)

 coefList <- vector("list",4)
 coefList[[1]] <- coefListSS
 coefList[[2]] <- coefListSC
 coefList[[3]] <- coefListAC
 coefList[[4]] <- coefListBC

 coefResult <- coefCheck(coefList)
 coefList   <- coefResult$coefList
 ntheta     <- coefResult$ntheta
```
Here variable \code{ntheta} will have value 3.

The model is set up with two homogeneous terms plus a forcing term for variable C.
```{r}
 SS <- make.Xterm(1, 1, 0, -1) # ncoef 1, variable 1, derivative 0, factor -1
 SC <- make.Xterm(2, 2, 0,  1) # ncoef 2, variable 1, derivative 0, factor  1
 CS <- make.Xterm(1, 3, 0,  1) # ncoef 3, variable 1, derivative 0, factor  1
 CC <- make.Xterm(2, 4, 0, -1) # ncoef 4, variable 1, derivative 0, factor -1
 #  define the homogeneous coefficient list for speed
 SXList <- vector("list",2)
 SXList[[1]] <- SS
 SXList[[2]] <- SC
 #  define the homogeneous coefficient list for control
 CXList <- vector("list",2)
 CXList[[1]] <- CS
 CXList[[2]] <- CC
 CF <- make.Fterm(3, SetPtfd, 1)
 CFList <- vector("list",1)
 CFList[[1]] <- CF
 #  define the two variables
 eqnorder <- 1
 SList <- make.variable("Speed",   eqnorder, SXList, NULL)
 CList <- make.variable("Control", eqnorder, CXList, CFList)
 #  load the two variables into a model list
 cruiseList <- vector("list",2)
 cruiseList[[1]] <- SList
 cruiseList[[2]] <- CList
 #  check the model list
 cruiseList <- modelCheck(cruiseList, coefList)
```
We now provide simnulated noisy data values in a list vector of length 2 observed for the values in \code{tobs}, and also the true values over the fine mesh \code{tfine} .
```{r}
yList <- vector("list",2)
Sdata <- list(argvals=tobs, y=yobs[,1])
Cdata <- list(argvals=tobs, y=yobs[,2])
yList[[1]] = Sdata
yList[[2]] = Cdata
```
The final step is to set up basis objects for the values of the two variables. The acceleraton of the speed variable will be smooth but the acceleration of the control variable will change discontinuously at the points where the forcing function changes values in a stepwise fashion.  For this reason the speed B-spline basis is of order five but the control variable is of order four.  We use three knots at the points of input change in order to capture these degrees of smoothness.  We also position a single knot between each interval between change points.
```{r}
#  set up knots
knots   <- c(seq(0,20,2),20,seq(20,40,2),40,seq(40,60,2),60,seq(60,80,2))
nknots  <- length(knots)
#  define speed basis
nSorder <- 5
#nSbasis <- nknots + nSorder - 2
#Sbasis  <- create.bspline.basis(rng, nSbasis, nSorder, knots)
nSbasis = 7
Sbasis  = create.bspline.basis(rng, nSbasis, nSorder)
#  define control basis
nCorder <- 4
#nCbasis <- nknots + nCorder - 2
#Cbasis  <- create.bspline.basis(rng, nCbasis, nCorder, knots)
nCbasis = 6
Cbasis  = create.bspline.basis(rng, nCbasis, nCorder)
#  set up the basis list object
XbasisList <- vector("list",2)
XbasisList[[1]] <- Sbasis
XbasisList[[2]] <- Cbasis
```
Now we manually evaluate the tensors for this problem.  The Btensor List is length 2, one for each variable, and each of these lists has a 3 by 3 list array within it.
```{r}
BtensorList  = Btensorfn(XbasisList, cruiseList, coefList)
```
We do a preliminary evaluation of the least squares criterion at the parameter values that we have set up in \code{coefList}.  This also assembles the four-way tensors that are used  repeatedly in subsequent computation.
```{r}
rhoVec = 0.5*matrix(1,1,2)
Data2LDList <- Data2LD(yList, XbasisList, cruiseList, coefList, rhoVec)
MSE     <- Data2LDList$MSE
DpMSE   <- Data2LDList$DpMSE
D2ppMSE <- Data2LDList$D2ppMSE
print("criterion:")
print(MSE)
print("gradient:")
print(DpMSE)
print("hessian:")
print(D2ppMSE)
```
We are now ready to optimize the criterion with respect to parameter values.  This involves the following call to function \code{Data2LD.opt}:  \code{Data2LD.opt(yList, XbasisList, cruiseList, coefList.opt, rho)}. 

Argument \code{rho} requires special comment, and a more detailed explanation of its meaning can be found in \cite{RamsayHooker17}.  \code{rho} may be either a single number greater than or equal to zero and less than one, or a vector of such numbers.  The role of these values is to control the relative emphasis on fitting the data versus satisfying the differential equation.  For lower values such as 0.5, the data will be closely approximated but the resulting of the $x_i$"s will not fit the equation particularly well, and the estimates of the parameters in \code{theta.opt} will be relatively poor.  But values like 0.999 will place strong emphasis on fitting the differential equation and provide good parameter estimate, but with a possible degradation of the fit to the data.

For smaller values of \code{rho} the optimization proceeds rapidly, but if we proceed directly to use large values, the optimization becomes more difficult, and may terminate in a local minimum that is not globally optimal.  

We therefore recommend using a vector of values, and the optimization code will use these one after another, feeding the parameter estimates at each value on as initial values for the next optimization.  The values of \code{rho} be increasing, but not by equal steps.  Instead, using the formula $\rho = \exp(\gamma)/[1 + \exp(\gamma)]$ where the increasing values of $\gamma$ can be integer sequences such as 0, 1, ..., 7, which values the values of $\rho$ as 0.5, 0.73, 0.88, 0.95, 0.98, 0.99, 0.997, and 0.999.

Here is a setup of this nature:
```{r}
dbglev  <-  1             #  debugging level
iterlim <- 50             #  maximum number of iterations
convrg  <- c(1e-4)  #  convergence criteria
#  set up the values of rho, one row per variable, one column per rho value
Gvec    <- 0:8
rhoVec  <- matrix(exp(Gvec)/(1+exp(Gvec)),1,9)
rhoMat  <- matrix(1,2,1) %*% rhoVec
nrho    <- dim(rhoMat)[2]
# matrices to store the values
dfesave   <- matrix(0,nrho,1)
gcvsave   <- matrix(0,nrho,1)
MSEsave   <- matrix(0,nrho,2)
thetasave <- matrix(0,nrho,3)
# the coefficients change with values of rho, the initial value is set here
coefList.opt <- coefList
#  loop through the values of rho
for (irho in 1:nrho) {
    rhoveci <- rhoMat[,irho]
    cat("\n")
    cat(" rhoveci = ", round(t(rhoveci),5), 
                " ------------------")
    cat("\n")
    irho = 1
    rhoi <- rhoMat[,irho]
    optResulti       <- Data2LD.opt(yList, XbasisList, cruiseList, coefList.opt, rhoi,
                                    convrg, iterlim, dbglev)
    theta.opti       <- optResulti$thetastore    
    coefList.opt     <- modelVec2List(theta.opti, coefList.opt)
    Data2LDresult    <- Data2LD(yList, XbasisList, cruiseList, coefList.opt, rhoi)
    thetasave[irho,] <- theta.opti
    MSEsave[irho]    <- Data2LDresult$MSE 
    dfesave[irho]    <- Data2LDresult$df
    gcvsave[irho]    <- Data2LDresult$gcv
}
```

The first line of this setup set values that determine how much output function \code{Data2LD.opt} produces.  The setting here produces one line per iteration, but values of 2 or 3 produce more detailed results that can be used to diagnose problems encountered during optimization.  

The second line specifies two thresholds that must be satisfied before termination is declared.  The first quantity is the maximum change in a parameter from one iteration to the next, and the second is required root-mean-squared average of the gradient values.  The third line specifies the maximum number of iterations that is allowed.

The line after the invocation of \code{Data2LD.opt} hands the optimized parameter values in parameter vector \code{theta.opti} over as initial values for the next value of \code{rho}.

Either after the "for" loop, or as in this case after every optimization, a single invocation of \code{Data2LD} returns a variety of objects that can be used to display final results.

See Ramsay and Hooker (2017) for much more explanation of these objects.

Additional illustrations can be found in the Data2LD package demos.

# References

* Kokoszka, P. (2017) *Introduction to Functional Data Analysis}. CRC Press.
* Ramsay, J. O., and Silverman, B. W.. (2005) *Functional Data Analysis}. New York: Springer.
* Ramsay, J. O., Hooker, G. and Graves, S. (2009) *Functional Data Analysis in R and Matlab}. New York: Springer.
* Ramsay, J. O. and Hooker, G. (2017) *Dynamic Data Analysis}. New York: Springer.


